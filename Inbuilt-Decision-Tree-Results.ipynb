{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, classification_report\nimport numpy as np\nimport pandas as pd\n\nX_raw = np.stack([acc_x.values, acc_y.values, acc_z.values], axis=-1)  # shape (n_samples, 128, 3)\nX_raw = X_raw.reshape(X_raw.shape[0], -1)  # flatten to (n_samples, 384)\ny_true = pd.read_csv('/kaggle/input/uci-har-dataset/UCI HAR Dataset/train/y_train.txt', header=None)[0]\nX_train_raw, X_test_raw, y_train_raw, y_test_raw = train_test_split(X_raw, y_true, test_size=0.2, random_state=42)\n\nclf_raw = DecisionTreeClassifier(random_state=42)\nclf_raw.fit(X_train_raw, y_train_raw)\ny_pred_raw = clf_raw.predict(X_test_raw)\n\nprint(\"Raw Accelerometer Data:\")\nprint(\"Accuracy:\", accuracy_score(y_test_raw, y_pred_raw))\nprint(\"Precision:\", precision_score(y_test_raw, y_pred_raw, average='weighted'))\nprint(\"Recall:\", recall_score(y_test_raw, y_pred_raw, average='weighted'))\nprint(\"Confusion Matrix:\\n\", confusion_matrix(y_test_raw, y_pred_raw))\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nX_train_tsfel, X_test_tsfel, y_train_tsfel, y_test_tsfel = train_test_split(Tsfel_Features, y_true, test_size=0.2, random_state=42)\nclf_tsfel = DecisionTreeClassifier(random_state=42)\nclf_tsfel.fit(X_train_tsfel, y_train_tsfel)\ny_pred_tsfel = clf_tsfel.predict(X_test_tsfel)\n\nprint(\"\\n TSFEL Features:\")\nprint(\"Accuracy:\", accuracy_score(y_test_tsfel, y_pred_tsfel))\nprint(\"Precision:\", precision_score(y_test_tsfel, y_pred_tsfel, average='weighted'))\nprint(\"Recall:\", recall_score(y_test_tsfel, y_pred_tsfel, average='weighted'))\nprint(\"Confusion Matrix:\\n\", confusion_matrix(y_test_tsfel, y_pred_tsfel))\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n# X_provided = pd.read_csv('/kaggle/input/uci-har-dataset/UCI HAR Dataset/train/X_train.txt', delim_whitespace=True, header=None).values\nX_train_prov, X_test_prov, y_train_prov, y_test_prov = train_test_split(X_reduced, y_true, test_size=0.2, random_state=42)\n\nclf_prov = DecisionTreeClassifier(random_state=42)\nclf_prov.fit(X_train_prov, y_train_prov)\ny_pred_prov = clf_prov.predict(X_test_prov)\n\nprint(\"\\n Provided Features :\")\nprint(\"Accuracy:\", accuracy_score(y_test_prov, y_pred_prov))\nprint(\"Precision:\", precision_score(y_test_prov, y_pred_prov, average='weighted'))\nprint(\"Recall:\", recall_score(y_test_prov, y_pred_prov, average='weighted'))\nprint(\"Confusion Matrix:\\n\", confusion_matrix(y_test_prov, y_pred_prov))\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"1. Raw data is noisy and high-dimensional, making it harder for the decision tree to identify class boundaries clearly.\n2. TSFEL extracts meaningful temporal and statistical patterns (e.g., energy, mean, std), helping the decision tree         learn better rules.\n3. These are precomputed time-domain and frequency-domain features, possibly less flexible than TSFEL’s dynamic             selection.","metadata":{}},{"cell_type":"markdown","source":"**Best Model: TSFEL-based model**\n\nIt slightly outperforms the one trained on provided features and vastly improves over raw signal-based classification.","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import train_test_split\n\n# X_raw, y_raw           → Raw accelerometer flattened windows\n# X_tsfel, y_tsfel       → TSFEL features\n# X_provided, y_provided → Provided dataset features\n\ny_raw=y_true\nX_tsfel=Tsfel_Features\ny_tsfel=y_true\ny_provided=y_true\n\ndef evaluate_model_depths(X, y, label):\n    accuracies = []\n    for depth in range(2, 40,2):\n        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n        clf = DecisionTreeClassifier(max_depth=depth, random_state=42)\n        clf.fit(X_train, y_train)\n        y_pred = clf.predict(X_test)\n        acc = accuracy_score(y_test, y_pred)\n        accuracies.append(acc)\n    return accuracies\n\ndepths = list(range(2, 40,2))\n\nacc_raw = evaluate_model_depths(X_raw, y_raw, \"Raw\")\nacc_tsfel = evaluate_model_depths(X_tsfel, y_tsfel, \"TSFEL\")\nacc_provided = evaluate_model_depths(X_reduced, y_provided, \"Provided\")\n\n# Plot\nplt.figure(figsize=(10, 6))\nplt.plot(depths, acc_raw, marker='o', label='Raw Accelerometer')\nplt.plot(depths, acc_tsfel, marker='s', label='TSFEL Features')\nplt.plot(depths, acc_provided, marker='^', label='Provided Features')\nplt.xlabel(\"Tree Depth\")\nplt.ylabel(\"Test Accuracy\")\nplt.title(\"Decision Tree Accuracy vs Depth\")\nplt.grid(True)\nplt.legend()\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"| Feature Type           | Accuracy | Optimal Depth   | Insights                                      |\n|------------------------|----------|-----------------|----------------------------------------------|\n| Raw Accelerometer      | ~81%     | 20              | Noisy data, less informative                 |\n| TSFEL Features         | ~95%     | 10              | Custom extracted features, very effective    |\n| Provided Features      | ~95%     | 10              | Clean, domain-specific, very effective       |","metadata":{}},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing import StandardScaler\nimport tsfel\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import accuracy_score\n\n# ---------- Load signals ----------\ndef load_signals(folder, signal_name):\n    path = f\"/kaggle/input/uci-har-dataset/UCI HAR Dataset/{folder}/Inertial Signals/{signal_name}\"\n    return np.loadtxt(path)\n\nax_train = load_signals('train', 'total_acc_x_train.txt')\nay_train = load_signals('train', 'total_acc_y_train.txt')\naz_train = load_signals('train', 'total_acc_z_train.txt')\ny_train = np.loadtxt(\"/kaggle/input/uci-har-dataset/UCI HAR Dataset/train/y_train.txt\").astype(int)\n\nax_test = load_signals('test', 'total_acc_x_test.txt')\nay_test = load_signals('test', 'total_acc_y_test.txt')\naz_test = load_signals('test', 'total_acc_z_test.txt')\ny_test = np.loadtxt(\"/kaggle/input/uci-har-dataset/UCI HAR Dataset/test/y_test.txt\").astype(int)\n\n# ---------- Configure TSFEL ----------\ncfg = tsfel.get_features_by_domain()\n\ndef extract_features_tsfel(signal_array, fs=50):  # for example, fs=50 Hz\n    features_list = []\n    for row in signal_array:\n        df_row = pd.DataFrame(row)\n        features = tsfel.time_series_features_extractor(cfg, df_row, fs=fs, verbose=0)\n        feature_values = np.nan_to_num(features.values[0])\n        features_list.append(feature_values)\n    return np.array(features_list)\n\n\n# Train features\nfeat_ax = extract_features_tsfel(ax_train)\nfeat_ay = extract_features_tsfel(ay_train)\nfeat_az = extract_features_tsfel(az_train)\nX_train = np.hstack([feat_ax, feat_ay, feat_az])\n\n# Test features\nfeat_ax_test = extract_features_tsfel(ax_test)\nfeat_ay_test = extract_features_tsfel(ay_test)\nfeat_az_test = extract_features_tsfel(az_test)\nX_test = np.hstack([feat_ax_test, feat_ay_test, feat_az_test])\n\n# ---------- Scale ----------\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\n# ---------- Train ----------\ntree = DecisionTreeClassifier(random_state=42, max_depth=5)\ntree.fit(X_train_scaled, y_train)\nprint(\"✅ Training completed.\")\n\n# ---------- Test accuracy ----------\ny_pred = tree.predict(X_test_scaled)\nprint(\"Accuracy on official test set:\", accuracy_score(y_test, y_pred))\n\n# ---------- New collected data ----------\nbase_path = '/kaggle/input/d/dinesh168/collected-data/Collected data'\nactivities = ['Laying', 'Sitting', 'Standing', 'Walking', 'Walking_Downstairs', 'Walking_Upstairs']\n\nlabel_map = {\n    1: 'Walking',\n    2: 'Walking_Upstairs',\n    3: 'Walking_Downstairs',\n    4: 'Sitting',\n    5: 'Standing',\n    6: 'Laying'\n}\n\nfeature_list = []\ntrue_labels = []\nfile_names = []\n\nfor activity in activities:\n    path = os.path.join(base_path, activity)\n    for file in os.listdir(path):\n        df = pd.read_csv(os.path.join(path, file), header=None)\n        df = df.apply(pd.to_numeric, errors='coerce')\n        df.dropna(inplace=True)\n        df.columns = ['acc_x', 'acc_y', 'acc_z'][:df.shape[1]]\n\n        if len(df) < 128:\n            continue\n        window = df.iloc[:128]\n\n        tsfel_features_all_axes = []\n        for axis in ['acc_x', 'acc_y', 'acc_z']:\n            sig_df = pd.DataFrame(window[axis].values)\n            tsfel_feat_df = tsfel.time_series_features_extractor(cfg, sig_df, verbose=0)\n            tsfel_feat = np.nan_to_num(tsfel_feat_df.values.flatten())\n            tsfel_features_all_axes.append(tsfel_feat)\n\n        final_features = np.concatenate(tsfel_features_all_axes)\n        feature_list.append(final_features)\n        true_labels.append(activity)\n        file_names.append(file)\n\n# ---------- Predict ----------\nX_new = np.array(feature_list)\nX_new_scaled = scaler.transform(X_new)\ny_pred_new = tree.predict(X_new_scaled)\n\n# ---------- Show results ----------\nfor fname, pred, true in zip(file_names, y_pred_new, true_labels):\n    pred_label = label_map.get(pred, \"Unknown\")\n    print(f\" {fname}: Predicted = {pred_label}, Actual = {true}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n\n# Convert y_pred_new integers to string labels\ny_pred_str = [label_map.get(pred, \"Unknown\") for pred in y_pred_new]\ny_true_str = true_labels\n\n# Calculate metrics\nacc = accuracy_score(y_true_str, y_pred_str)\nprec = precision_score(y_true_str, y_pred_str, average='weighted', zero_division=0)\nrec = recall_score(y_true_str, y_pred_str, average='weighted', zero_division=0)\nf1 = f1_score(y_true_str, y_pred_str, average='weighted', zero_division=0)\nconf_mat = confusion_matrix(y_true_str, y_pred_str, labels=list(label_map.values()))\n\nprint(\"✅ Metrics on collected data:\")\nprint(f\"Accuracy: {acc:.4f}\")\nprint(f\"Precision (weighted): {prec:.4f}\")\nprint(f\"Recall (weighted): {rec:.4f}\")\nprint(f\"F1-score (weighted): {f1:.4f}\")\nprint(\"\\nConfusion Matrix:\")\nprint(conf_mat)\n\nprint(\"\\nDetailed Classification Report:\")\nprint(classification_report(y_true_str, y_pred_str, zero_division=0))\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn.preprocessing import StandardScaler\nimport tsfel\n\n# ---------- Load UCI HAR signals ----------\ndef load_signals(folder, signal_name):\n    path = f\"/kaggle/input/uci-har-dataset/UCI HAR Dataset/{folder}/Inertial Signals/{signal_name}\"\n    return np.loadtxt(path)\n\nax_train = load_signals('train', 'total_acc_x_train.txt')\nay_train = load_signals('train', 'total_acc_y_train.txt')\naz_train = load_signals('train', 'total_acc_z_train.txt')\ny_train = np.loadtxt(\"/kaggle/input/uci-har-dataset/UCI HAR Dataset/train/y_train.txt\").astype(int)\n\n# ---------- Configure TSFEL ----------\ncfg = tsfel.get_features_by_domain()\n\ndef extract_features_tsfel(signal_array, fs=50):  # for example, fs=50 Hz\n    features_list = []\n    for row in signal_array:\n        df_row = pd.DataFrame(row)\n        features = tsfel.time_series_features_extractor(cfg, df_row, fs=fs, verbose=0)\n        feature_values = np.nan_to_num(features.values[0])\n        features_list.append(feature_values)\n    return np.array(features_list)\n\nfeat_ax = extract_features_tsfel(ax_train)\nfeat_ay = extract_features_tsfel(ay_train)\nfeat_az = extract_features_tsfel(az_train)\nX_har = np.hstack([feat_ax, feat_ay, feat_az])\ny_har = y_train\n\nimport os\n\nbase_path = '/kaggle/input/d/dinesh168/collected-data/Collected data'\nactivities = ['Laying', 'Sitting', 'Standing', 'Walking', 'Walking_Downstairs', 'Walking_Upstairs']\n\nlabel_reverse_map = {\n    'Walking': 1,\n    'Walking_Upstairs': 2,\n    'Walking_Downstairs': 3,\n    'Sitting': 4,\n    'Standing': 5,\n    'Laying': 6\n}\n\nfeature_list = []\nlabel_list = []\n\nfor activity in activities:\n    path = os.path.join(base_path, activity)\n    for file in os.listdir(path):\n        df = pd.read_csv(os.path.join(path, file), header=None)\n        df = df.apply(pd.to_numeric, errors='coerce')\n        df.dropna(inplace=True)\n        df.columns = ['acc_x', 'acc_y', 'acc_z'][:df.shape[1]]\n\n        if len(df) < 128:\n            continue\n\n        window = df.iloc[:128]\n        tsfel_features_all_axes = []\n        for axis in ['acc_x', 'acc_y', 'acc_z']:\n            sig_df = pd.DataFrame(window[axis].values)\n            tsfel_feat_df = tsfel.time_series_features_extractor(cfg, sig_df, verbose=0)\n            tsfel_feat = np.nan_to_num(tsfel_feat_df.values.flatten())\n            tsfel_features_all_axes.append(tsfel_feat)\n\n        final_features = np.concatenate(tsfel_features_all_axes)\n        feature_list.append(final_features)\n        label_list.append(label_reverse_map[activity])\n\nX_collected = np.array(feature_list)\ny_collected = np.array(label_list)\n\nimport os\n\nbase_path = '/kaggle/input/d/dinesh168/collected-data/Collected data'\nactivities = ['Laying', 'Sitting', 'Standing', 'Walking', 'Walking_Downstairs', 'Walking_Upstairs']\n\nlabel_reverse_map = {\n    'Walking': 1,\n    'Walking_Upstairs': 2,\n    'Walking_Downstairs': 3,\n    'Sitting': 4,\n    'Standing': 5,\n    'Laying': 6\n}\n\nfeature_list = []\nlabel_list = []\n\nfor activity in activities:\n    path = os.path.join(base_path, activity)\n    for file in os.listdir(path):\n        df = pd.read_csv(os.path.join(path, file), header=None)\n        df = df.apply(pd.to_numeric, errors='coerce')\n        df.dropna(inplace=True)\n        df.columns = ['acc_x', 'acc_y', 'acc_z'][:df.shape[1]]\n\n        if len(df) < 128:\n            continue\n\n        window = df.iloc[:128]\n        tsfel_features_all_axes = []\n        for axis in ['acc_x', 'acc_y', 'acc_z']:\n            sig_df = pd.DataFrame(window[axis].values)\n            tsfel_feat_df = tsfel.time_series_features_extractor(cfg, sig_df, verbose=0)\n            tsfel_feat = np.nan_to_num(tsfel_feat_df.values.flatten())\n            tsfel_features_all_axes.append(tsfel_feat)\n\n        final_features = np.concatenate(tsfel_features_all_axes)\n        feature_list.append(final_features)\n        label_list.append(label_reverse_map[activity])\n\nX_collected = np.array(feature_list)\ny_collected = np.array(label_list)\n\nfrom sklearn.utils import shuffle\n\n# Combine\nX_all = np.vstack([X_har, X_collected])\ny_all = np.hstack([y_har, y_collected])\n\n# Shuffle\nX_all, y_all = shuffle(X_all, y_all, random_state=42)\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\n\n# Scale\nscaler = StandardScaler()\nX_all_scaled = scaler.fit_transform(X_all)\n\n# Split\nX_train, X_test, y_train, y_test = train_test_split(X_all_scaled, y_all, test_size=0.2, random_state=42)\n\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, classification_report\n\ntree = DecisionTreeClassifier(random_state=42, max_depth=5)\nprint(\"Training started...\")\ntree.fit(X_train, y_train)\nprint(\" Training completed.\")\n\ny_pred = tree.predict(X_test)\n\nprint(\"\\n Metrics after combining & shuffling:\")\nprint(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\nprint(f\"Precision: {precision_score(y_test, y_pred, average='weighted'):.4f}\")\nprint(f\"Recall: {recall_score(y_test, y_pred, average='weighted'):.4f}\")\nprint(\"\\nDetailed Report:\")\nprint(classification_report(y_test, y_pred, zero_division=0))\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}